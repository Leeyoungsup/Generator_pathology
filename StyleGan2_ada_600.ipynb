{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:35:17.720897: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 16:35:18.432345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy.random as npr\n",
    "import os, time, gc, random\n",
    "import glob\n",
    "import PIL\n",
    "from tqdm.auto import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks used in GAN\n",
    "\n",
    "def minibatchStd(inputs):\n",
    "    inputs = tf.transpose(inputs, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "    group_size = tf.minimum(4, tf.shape(inputs)[0])             # Minibatch must be divisible by (or smaller than) group_size.\n",
    "    s = inputs.shape                                             # [NCHW]  Input shape.\n",
    "    y = tf.reshape(inputs, [group_size, -1, 1, s[1], s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
    "    y -= tf.reduce_mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n",
    "    y = tf.reduce_mean(tf.square(y), axis=0)                # [MncHW]  Calc variance over group.\n",
    "    y = tf.sqrt(y + eps)                                    # [MncHW]  Calc stddev over group.\n",
    "    y = tf.reduce_mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n",
    "    y = tf.reduce_mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n",
    "    y = tf.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n",
    "    y = tf.concat([inputs, y], axis=1)                        # [NCHW]  Append as new fmap.\n",
    "    y = tf.transpose(y, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "    return y\n",
    "\n",
    "class DiffUS(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        return super().__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        _N, H, W, C = inputs.shape.as_list()\n",
    "        x = K.reshape(inputs, (-1, H, 1, W, 1, C))\n",
    "        x = tf.tile(x, (1, 1, 2, 1, 2, 1))\n",
    "        used = K.reshape(x, (-1, H * 2, W * 2, C))\n",
    "        return used\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    noise, img = x\n",
    "    height = img.shape[1]\n",
    "    width = img.shape[2]\n",
    "    \n",
    "    return noise[:, :height, :width, :]\n",
    "\n",
    "ndist = tf.random_normal_initializer(0, 1)\n",
    "zeros = tf.zeros_initializer()\n",
    "ones = tf.ones_initializer()\n",
    "\n",
    "class FCE(Dense): # fully connected equalized\n",
    "    def __init__(self, units, kernel_initializer=ndist, bias_initializer=zeros, lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('fce', input_shape)\n",
    "        n = input_shape[-1] # input_shape = (None, features_in) or (None, dimY, dimX, features_in)\n",
    "        if self.lrelu:\n",
    "            self.scale = np.sqrt((1 / 0.6) / n) # he but not really, 1 / 0.6 since lrelu(0.2) makes scales variance to 0.6 (0.2 if neg, 1 if pos, div by 2) and you want them to be 1\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.dot(inputs, self.kernel * self.scale)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class CVE(Conv2D):\n",
    "    def __init__(self, units, kernel_size=3, kernel_initializer=ndist, bias_initializer=zeros, padding='same', lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, kernel_size, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.padding = padding\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('cve', self.kernel.shape)\n",
    "        n = np.prod(self.kernel.shape[:-1]) # self.kernel.shape = (kernel_x, kernel_y, features_in, features_out)\n",
    "        if self.lrelu: # he\n",
    "            self.scale = np.sqrt((1 / 0.6) / n)\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.conv2d(inputs, self.kernel * self.scale, padding=self.padding)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'padding': self.padding,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class ConvMod(Layer):\n",
    "    def __init__(self, nf, x, w, kSize=3, demod=True):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        self.kSize = kSize\n",
    "        self.xShape = x.shape\n",
    "        self.wShape = w.shape\n",
    "        self.scale = FCE(self.xShape[-1], bias_initializer=ones, lrelu=False)\n",
    "        self.conv = CVE(nf, kSize, lrelu=demod)\n",
    "        self.conv(x) # create kernel without doing it in build method so h5py doesn't go sicko mode\n",
    "        self.demod = demod\n",
    "\n",
    "    def build(self, input_shape): # input_shape: [TensorShape([None, 4, 4, 256]), TensorShape([None, 256]), TensorShape([None, 4, 4, 1])]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "\n",
    "        x = tf.transpose(x, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "        weight = self.conv.kernel[np.newaxis] * self.conv.scale # kkio -> 1kkio (1, kernel_size, kernel_size, input_features, output_features)\n",
    "\n",
    "        scale = self.scale(w)\n",
    "        scale = scale[:, np.newaxis, np.newaxis, :, np.newaxis] # Bs -> B, 1, 1, s, 1 (s - scaling factor)\n",
    "\n",
    "        wp = weight * scale # 1kkio * B11s1 -> Bkk(s*i)o\n",
    "        wpp = wp\n",
    "\n",
    "        if self.demod:\n",
    "            wStd = tf.math.rsqrt(tf.reduce_sum(tf.math.square(wp), axis=[1,2,3]) + 1e-8) # Bkkio -> Bo\n",
    "            wpp = wp * wStd[:, np.newaxis, np.newaxis, np.newaxis, :] # [BkkIO] Scale output feature maps.\n",
    "\n",
    "        x = tf.reshape(x, (1, -1, x.shape[2], x.shape[3])) # N, C, H, W -> 1, (N*C), H, W\n",
    "\n",
    "        # B, k, k, i, o -> k, k, i, B, o -> k, k, i, (B*o)\n",
    "        wpp = tf.reshape(tf.transpose(wpp, [1, 2, 3, 0, 4]), [wpp.shape[1], wpp.shape[2], wpp.shape[3], -1])\n",
    "\n",
    "        x = tf.nn.conv2d(x, wpp, padding='SAME', data_format='NCHW', strides=[1, 1, 1, 1]) # grouped conv\n",
    "        x = tf.reshape(x, (-1, self.nf, x.shape[2], x.shape[3])) # 1, (N*C), H, W -> N, C, H, W\n",
    "        x = tf.transpose(x, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "        x = K.bias_add(x, self.conv.bias)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_filters': self.nf,\n",
    "            'kernel_size': self.kSize,\n",
    "            'xShape': self.xShape,\n",
    "            'wShape': self.wShape,\n",
    "            'demodulated': self.demod\n",
    "                      })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing timer; 0.0051 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "# custom class to see how long tasks take\n",
    "class timeIt:\n",
    "    def __init__(self, description):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        self.running = True\n",
    "    \n",
    "    def new(self, description, verbose=True):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        \n",
    "        duration = time.time() - startTime\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "        \n",
    "        return duration\n",
    "    \n",
    "    def close(self, verbose=True):\n",
    "        duration = time.time() - self.start\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "            \n",
    "        self.start = None\n",
    "        self.description = None\n",
    "        self.running = False\n",
    "        return duration\n",
    "\n",
    "sess = timeIt('testing timer')\n",
    "time.sleep(0.005)\n",
    "_ = sess.close(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reals - numpy array of the training images; ds - batched TF dataset given to the GPU\n",
    "datasetPath = '../../data/patch_600_png/*.png'\n",
    "modelPath = '../../model/styleGAN2/600/'\n",
    "reals, ds = None, None\n",
    "gc.collect()\n",
    "\n",
    "batchSize = 4\n",
    "m = 1000 # amount of images stored in RAM (reduce if low RAM, increase if high RAM)\n",
    "m = min(m, int(len(glob.glob(datasetPath))))\n",
    "\n",
    "m = batchSize * (m // batchSize)\n",
    "imgSize =600# size of images in pixels\n",
    "zdim = imgSize # number of elements in a latent vector\n",
    "p = 0.0 # probability of data augmentation\n",
    "n = 4 # number of minibatches before p is changed\n",
    "numImgsStep = 5e5 # number of images needed to change p from 0 -> 1 or 1 -> 0\n",
    "pStep = n * batchSize / numImgsStep # how much p increases/decreases per n minibatches\n",
    "eps = 1e-8 # epsilon, small number used to prevent NaN errors\n",
    "pplEMA = 0.0 # exponential moving average for average PPL for PPL reg.\n",
    "discLayerFilters = np.linspace(32,imgSize,int(np.log2(imgSize/8)),dtype=np.int32)\n",
    "genLayerFilters = np.linspace(imgSize,32,int(np.log2(imgSize/8)),dtype=np.int32)\n",
    "w1_range=int(np.log2(imgSize/2)/2)\n",
    "w2_range=int(np.log2(imgSize/2)/2+(np.log2(imgSize/2)%2>=0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cf7c981c4645f5af0d6297238fe112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:37:33.922773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38374 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data; 137.7026 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "'''\n",
    "goes into datasetPath, chooses and stores image data from random files (repeats allowed)\n",
    "into a np array, converts the array into the TF dataset\n",
    "\n",
    "Args:\n",
    "others - random indices for files to choose to train the GAN on\n",
    "verbose - determines whether duration to complete is printed out or not\n",
    "'''\n",
    "def loadData(others=None, verbose=True):\n",
    "    global reals, ds, m\n",
    "    sess = timeIt('Loading data')\n",
    "    reals, ds = None, None\n",
    "    gc.collect()\n",
    "    files = glob.glob(datasetPath)\n",
    "    \n",
    "    reals = np.zeros((len(files), imgSize, imgSize, 3))\n",
    "    for i in tqdm(range(len(files))):\n",
    "        strI = str(files[i])\n",
    "        img1=PIL.Image.open(strI).convert(\"RGB\")\n",
    "        if(img1.size[0]>=img1.size[1]):\n",
    "            ratio=imgSize/img1.size[0]\n",
    "        else:\n",
    "            ratio=imgSize/img1.size[1]\n",
    "        width=ratio*img1.size[0]\n",
    "        height=ratio*img1.size[1]\n",
    "        height_padding_size=int((imgSize-height)/2)\n",
    "        width_padding_size=int((imgSize-width)/2)\n",
    "        img1=np.array(img1.resize((int(width),int(height))))\n",
    "        reals[i] = img1\n",
    "        del img1\n",
    "    \n",
    "    reals = reals[:m].astype(np.float32)/127.5-1.0\n",
    "\n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(reals).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "    sess.close(verbose=verbose)\n",
    "    \n",
    "def aug(imgs, p):\n",
    "    augImgs = imgs\n",
    "    def augCond(x):\n",
    "        randInds = tf.random.uniform((batchSize,))\n",
    "        trueCond = tf.cast(randInds < p, tf.float32) # using tf.cast to turn booleans into ones and zeros\n",
    "        falseCond = tf.cast(randInds >= p, tf.float32)\n",
    "        auged = x * tf.reshape(trueCond, (batchSize, 1, 1, 1)) + augImgs * tf.reshape(falseCond, (batchSize, 1, 1, 1))\n",
    "        return auged\n",
    "    \n",
    "    height = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    width = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    boxLite = tf.random.uniform((batchSize, 2), maxval=(1-height, 1-width))\n",
    "    boxes = tf.concat([boxLite, tf.transpose(boxLite[:, 0][np.newaxis]) + height, tf.transpose(boxLite[:, 1][np.newaxis]) + width], axis=1)\n",
    "    boxLiteIso = tf.random.uniform((batchSize, 1), maxval=1-height)\n",
    "    boxIso = tf.concat([boxLite, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height], axis=1)\n",
    "    rot90s = np.pi * 90 * tf.cast(tf.random.uniform((batchSize,), minval=0, maxval=4, dtype=tf.int32), tf.float32) / 180\n",
    "    augImgs = augCond(tf.image.random_brightness(augImgs, max_delta=0.25))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxIso, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxes, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, rot90s))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, tf.random.uniform((batchSize,), minval=-np.pi/6, maxval=np.pi/6)))\n",
    "    augImgs = augCond(tfa.image.translate(augImgs, tf.random.normal((batchSize, 2), 0, imgSize // 10)))\n",
    "    return augImgs\n",
    "loadData()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generator style block.\n",
    "Args:\n",
    "accum - accumulated output from the input/output skips\n",
    "x - the non-RGB image input\n",
    "w - the style (output of the mapping function with input of the latent vector)\n",
    "noiseInp - normally distributed noise\n",
    "filters - number of channels/feature maps the output of the style block will have\n",
    "us - whether or not to upsample the images\n",
    "'''\n",
    "def gblock(accum, x, w, noiseInp, filters, us=True):\n",
    "    if us:\n",
    "        x = DiffUS()(x) # using custom upsampling function since other upsampling methods didn't provide gradients of their gradients\n",
    "        accum = DiffUS()(accum)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = ConvMod(filters, x, w)([x, w])\n",
    "        noise = Lambda(crop_to_fit)([noiseInp, x]) # crop noises so it can be added with x\n",
    "        noise = FCE(filters, kernel_initializer=zeros, use_bias=False, lrelu=False)(noise) #scale noises\n",
    "        x = Add()([x, noise])\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    trgb = ConvMod(3, x, w, 1, demod=False)([x, w]) # toRGB 1x1 convolution\n",
    "    accum = Add()([accum, trgb]) * np.sqrt(1 / 2) # the sqrt(1/2) not included in original StyleGAN2 but i didn't see why not\n",
    "        \n",
    "    return accum, x\n",
    "\n",
    "# Discriminator block.\n",
    "def dblock(x, filters, maxFilters=256):\n",
    "    frgb = CVE(min(2 * filters, maxFilters), 1, lrelu=False, use_bias=False)(x)\n",
    "    \n",
    "    x = CVE(filters)(x)\n",
    "    x = CVE(min(2 * filters, maxFilters))(x)\n",
    "        \n",
    "    frgb = AveragePooling2D()(frgb)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Add()([x, frgb])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBlocks = int(np.log2(imgSize / 8)) # number of upsampled style blocks\n",
    "\n",
    "# mapper architecture\n",
    "def ztow(nlayers=8):\n",
    "    z = Input((zdim,))\n",
    "    w = z\n",
    "    if nlayers > 0:\n",
    "        w = LayerNormalization()(w)\n",
    "    for i in range(max(nlayers-1, 0)):\n",
    "        w = FCE(zdim)(w)\n",
    "    return Model(z, w, name='mapping')\n",
    "\n",
    "# generator architecture\n",
    "def genGen():\n",
    "    ws = [Input((zdim,), name='w{}'.format(i)) for i in range(nBlocks+1)]\n",
    "    noiseInp = Input((imgSize, imgSize, 1), name='noiseInp')\n",
    "\n",
    "    x = Dense(1)(ws[0]); x = Lambda(lambda x: x * 0 + 1)(x)\n",
    "    x = FCE(8*8*zdim, lrelu=False, use_bias=False)(x)\n",
    "    x = Reshape((8, 8, zdim))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = ConvMod(genLayerFilters[0], x, ws[0])([x, ws[0]])\n",
    "    noise = Lambda(crop_to_fit)([noiseInp, x])\n",
    "    noise = FCE(genLayerFilters[0], kernel_initializer=zeros, use_bias=False, lrelu=False)(noise)\n",
    "    x = Add()([x, noise])\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    accum = ConvMod(3, x, ws[0], 1, demod=False)([x, ws[0]])\n",
    "    \n",
    "    for idx, f in enumerate(genLayerFilters):\n",
    "        accum, x = gblock(accum, x, ws[idx+1], noiseInp, f)\n",
    "        \n",
    "    out = CVE(3, 1, lrelu=False)(accum)\n",
    "    return Model([*ws, noiseInp], out, name='generator')\n",
    "      \n",
    "# discriminator architecture  \n",
    "def genDisc():\n",
    "    inp = Input((imgSize, imgSize, 3)); x = inp\n",
    "\n",
    "    \n",
    "    x = CVE(discLayerFilters[0], 1)(x)\n",
    "    for fi, f in enumerate(discLayerFilters):\n",
    "        x = dblock(x, f, maxFilters=discLayerFilters[-1])\n",
    "    \n",
    "    x = Lambda(minibatchStd)(x)\n",
    "    x = CVE(discLayerFilters[-1])(x)\n",
    "    x = Flatten()(x)\n",
    "    x = FCE(discLayerFilters[-1])(x)\n",
    "    out = FCE(1, lrelu=False)(x)\n",
    "\n",
    "    return Model(inp, out, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids, gcosts, dcosts = [], [], []\n",
    "pplNorms = []\n",
    "gpcosts = []\n",
    "ps, rts = [], []\n",
    "\n",
    "\n",
    "mapper = ztow()\n",
    "generator = genGen()\n",
    "discriminator = genDisc()\n",
    "inception = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(imgSize, imgSize, 3)) # for FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " w0 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            601         ['w0[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_112 (Lambda)            (None, 1)            0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " fce_326 (FCE)                  (None, 38400)        38400       ['lambda_112[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 8, 8, 600)    0           ['fce_326[0][0]']                \n",
      "                                                                                                  \n",
      " conv_mod_153 (ConvMod)         (None, 8, 8, 600)    3601200     ['reshape_7[0][0]',              \n",
      "                                                                  'w0[0][0]']                     \n",
      "                                                                                                  \n",
      " noiseInp (InputLayer)          [(None, 600, 600, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " lambda_113 (Lambda)            (None, 8, 8, 1)      0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_153[0][0]']           \n",
      "                                                                                                  \n",
      " fce_328 (FCE)                  (None, 8, 8, 600)    600         ['lambda_113[0][0]']             \n",
      "                                                                                                  \n",
      " add_180 (Add)                  (None, 8, 8, 600)    0           ['conv_mod_153[0][0]',           \n",
      "                                                                  'fce_328[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_113 (LeakyReLU)    (None, 8, 8, 600)    0           ['add_180[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_94 (DiffUS)            (None, 16, 16, 600)  0           ['leaky_re_lu_113[0][0]']        \n",
      "                                                                                                  \n",
      " w1 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " conv_mod_155 (ConvMod)         (None, 16, 16, 600)  3601200     ['diff_us_94[0][0]',             \n",
      "                                                                  'w1[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_114 (Lambda)            (None, 16, 16, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_155[0][0]']           \n",
      "                                                                                                  \n",
      " fce_331 (FCE)                  (None, 16, 16, 600)  600         ['lambda_114[0][0]']             \n",
      "                                                                                                  \n",
      " add_181 (Add)                  (None, 16, 16, 600)  0           ['conv_mod_155[0][0]',           \n",
      "                                                                  'fce_331[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_114 (LeakyReLU)    (None, 16, 16, 600)  0           ['add_181[0][0]']                \n",
      "                                                                                                  \n",
      " conv_mod_156 (ConvMod)         (None, 16, 16, 600)  3601200     ['leaky_re_lu_114[0][0]',        \n",
      "                                                                  'w1[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_115 (Lambda)            (None, 16, 16, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_156[0][0]']           \n",
      "                                                                                                  \n",
      " fce_333 (FCE)                  (None, 16, 16, 600)  600         ['lambda_115[0][0]']             \n",
      "                                                                                                  \n",
      " add_182 (Add)                  (None, 16, 16, 600)  0           ['conv_mod_156[0][0]',           \n",
      "                                                                  'fce_333[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_115 (LeakyReLU)    (None, 16, 16, 600)  0           ['add_182[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_96 (DiffUS)            (None, 32, 32, 600)  0           ['leaky_re_lu_115[0][0]']        \n",
      "                                                                                                  \n",
      " w2 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " conv_mod_158 (ConvMod)         (None, 32, 32, 486)  2985486     ['diff_us_96[0][0]',             \n",
      "                                                                  'w2[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_116 (Lambda)            (None, 32, 32, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_158[0][0]']           \n",
      "                                                                                                  \n",
      " fce_336 (FCE)                  (None, 32, 32, 486)  486         ['lambda_116[0][0]']             \n",
      "                                                                                                  \n",
      " add_184 (Add)                  (None, 32, 32, 486)  0           ['conv_mod_158[0][0]',           \n",
      "                                                                  'fce_336[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_116 (LeakyReLU)    (None, 32, 32, 486)  0           ['add_184[0][0]']                \n",
      "                                                                                                  \n",
      " conv_mod_159 (ConvMod)         (None, 32, 32, 486)  2418336     ['leaky_re_lu_116[0][0]',        \n",
      "                                                                  'w2[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_117 (Lambda)            (None, 32, 32, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_159[0][0]']           \n",
      "                                                                                                  \n",
      " fce_338 (FCE)                  (None, 32, 32, 486)  486         ['lambda_117[0][0]']             \n",
      "                                                                                                  \n",
      " add_185 (Add)                  (None, 32, 32, 486)  0           ['conv_mod_159[0][0]',           \n",
      "                                                                  'fce_338[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_117 (LeakyReLU)    (None, 32, 32, 486)  0           ['add_185[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_98 (DiffUS)            (None, 64, 64, 486)  0           ['leaky_re_lu_117[0][0]']        \n",
      "                                                                                                  \n",
      " w3 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " conv_mod_161 (ConvMod)         (None, 64, 64, 372)  1919586     ['diff_us_98[0][0]',             \n",
      "                                                                  'w3[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_118 (Lambda)            (None, 64, 64, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_161[0][0]']           \n",
      "                                                                                                  \n",
      " fce_341 (FCE)                  (None, 64, 64, 372)  372         ['lambda_118[0][0]']             \n",
      "                                                                                                  \n",
      " add_187 (Add)                  (None, 64, 64, 372)  0           ['conv_mod_161[0][0]',           \n",
      "                                                                  'fce_341[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_118 (LeakyReLU)    (None, 64, 64, 372)  0           ['add_187[0][0]']                \n",
      "                                                                                                  \n",
      " conv_mod_162 (ConvMod)         (None, 64, 64, 372)  1469400     ['leaky_re_lu_118[0][0]',        \n",
      "                                                                  'w3[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_119 (Lambda)            (None, 64, 64, 1)    0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_162[0][0]']           \n",
      "                                                                                                  \n",
      " fce_343 (FCE)                  (None, 64, 64, 372)  372         ['lambda_119[0][0]']             \n",
      "                                                                                                  \n",
      " add_188 (Add)                  (None, 64, 64, 372)  0           ['conv_mod_162[0][0]',           \n",
      "                                                                  'fce_343[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_119 (LeakyReLU)    (None, 64, 64, 372)  0           ['add_188[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_100 (DiffUS)           (None, 128, 128, 37  0           ['leaky_re_lu_119[0][0]']        \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " w4 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " conv_mod_164 (ConvMod)         (None, 128, 128, 25  1090963     ['diff_us_100[0][0]',            \n",
      "                                9)                                'w4[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_120 (Lambda)            (None, 128, 128, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_164[0][0]']           \n",
      "                                                                                                  \n",
      " fce_346 (FCE)                  (None, 128, 128, 25  259         ['lambda_120[0][0]']             \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " add_190 (Add)                  (None, 128, 128, 25  0           ['conv_mod_164[0][0]',           \n",
      "                                9)                                'fce_346[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_120 (LeakyReLU)    (None, 128, 128, 25  0           ['add_190[0][0]']                \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " conv_mod_165 (ConvMod)         (None, 128, 128, 25  759647      ['leaky_re_lu_120[0][0]',        \n",
      "                                9)                                'w4[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_121 (Lambda)            (None, 128, 128, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_165[0][0]']           \n",
      "                                                                                                  \n",
      " fce_348 (FCE)                  (None, 128, 128, 25  259         ['lambda_121[0][0]']             \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " add_191 (Add)                  (None, 128, 128, 25  0           ['conv_mod_165[0][0]',           \n",
      "                                9)                                'fce_348[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_121 (LeakyReLU)    (None, 128, 128, 25  0           ['add_191[0][0]']                \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " diff_us_102 (DiffUS)           (None, 256, 256, 25  0           ['leaky_re_lu_121[0][0]']        \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " w5 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " conv_mod_167 (ConvMod)         (None, 256, 256, 14  493799      ['diff_us_102[0][0]',            \n",
      "                                5)                                'w5[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_122 (Lambda)            (None, 256, 256, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_167[0][0]']           \n",
      "                                                                                                  \n",
      " fce_351 (FCE)                  (None, 256, 256, 14  145         ['lambda_122[0][0]']             \n",
      "                                5)                                                                \n",
      "                                                                                                  \n",
      " add_193 (Add)                  (None, 256, 256, 14  0           ['conv_mod_167[0][0]',           \n",
      "                                5)                                'fce_351[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_122 (LeakyReLU)    (None, 256, 256, 14  0           ['add_193[0][0]']                \n",
      "                                5)                                                                \n",
      "                                                                                                  \n",
      " conv_mod_154 (ConvMod)         (None, 8, 8, 3)      362403      ['leaky_re_lu_113[0][0]',        \n",
      "                                                                  'w0[0][0]']                     \n",
      "                                                                                                  \n",
      " conv_mod_168 (ConvMod)         (None, 256, 256, 14  276515      ['leaky_re_lu_122[0][0]',        \n",
      "                                5)                                'w5[0][0]']                     \n",
      "                                                                                                  \n",
      " diff_us_95 (DiffUS)            (None, 16, 16, 3)    0           ['conv_mod_154[0][0]']           \n",
      "                                                                                                  \n",
      " conv_mod_157 (ConvMod)         (None, 16, 16, 3)    362403      ['leaky_re_lu_115[0][0]',        \n",
      "                                                                  'w1[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_123 (Lambda)            (None, 256, 256, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_168[0][0]']           \n",
      "                                                                                                  \n",
      " add_183 (Add)                  (None, 16, 16, 3)    0           ['diff_us_95[0][0]',             \n",
      "                                                                  'conv_mod_157[0][0]']           \n",
      "                                                                                                  \n",
      " fce_353 (FCE)                  (None, 256, 256, 14  145         ['lambda_123[0][0]']             \n",
      "                                5)                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_46 (TFOpLambd  (None, 16, 16, 3)   0           ['add_183[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_194 (Add)                  (None, 256, 256, 14  0           ['conv_mod_168[0][0]',           \n",
      "                                5)                                'fce_353[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_97 (DiffUS)            (None, 32, 32, 3)    0           ['tf.math.multiply_46[0][0]']    \n",
      "                                                                                                  \n",
      " conv_mod_160 (ConvMod)         (None, 32, 32, 3)    293547      ['leaky_re_lu_117[0][0]',        \n",
      "                                                                  'w2[0][0]']                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_123 (LeakyReLU)    (None, 256, 256, 14  0           ['add_194[0][0]']                \n",
      "                                5)                                                                \n",
      "                                                                                                  \n",
      " add_186 (Add)                  (None, 32, 32, 3)    0           ['diff_us_97[0][0]',             \n",
      "                                                                  'conv_mod_160[0][0]']           \n",
      "                                                                                                  \n",
      " diff_us_104 (DiffUS)           (None, 512, 512, 14  0           ['leaky_re_lu_123[0][0]']        \n",
      "                                5)                                                                \n",
      "                                                                                                  \n",
      " w6 (InputLayer)                [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_47 (TFOpLambd  (None, 32, 32, 3)   0           ['add_186[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " conv_mod_170 (ConvMod)         (None, 512, 512, 32  128937      ['diff_us_104[0][0]',            \n",
      "                                )                                 'w6[0][0]']                     \n",
      "                                                                                                  \n",
      " diff_us_99 (DiffUS)            (None, 64, 64, 3)    0           ['tf.math.multiply_47[0][0]']    \n",
      "                                                                                                  \n",
      " conv_mod_163 (ConvMod)         (None, 64, 64, 3)    224691      ['leaky_re_lu_119[0][0]',        \n",
      "                                                                  'w3[0][0]']                     \n",
      "                                                                                                  \n",
      " lambda_124 (Lambda)            (None, 512, 512, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_170[0][0]']           \n",
      "                                                                                                  \n",
      " add_189 (Add)                  (None, 64, 64, 3)    0           ['diff_us_99[0][0]',             \n",
      "                                                                  'conv_mod_163[0][0]']           \n",
      "                                                                                                  \n",
      " fce_356 (FCE)                  (None, 512, 512, 32  32          ['lambda_124[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_48 (TFOpLambd  (None, 64, 64, 3)   0           ['add_189[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_196 (Add)                  (None, 512, 512, 32  0           ['conv_mod_170[0][0]',           \n",
      "                                )                                 'fce_356[0][0]']                \n",
      "                                                                                                  \n",
      " diff_us_101 (DiffUS)           (None, 128, 128, 3)  0           ['tf.math.multiply_48[0][0]']    \n",
      "                                                                                                  \n",
      " conv_mod_166 (ConvMod)         (None, 128, 128, 3)  156439      ['leaky_re_lu_121[0][0]',        \n",
      "                                                                  'w4[0][0]']                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_124 (LeakyReLU)    (None, 512, 512, 32  0           ['add_196[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_192 (Add)                  (None, 128, 128, 3)  0           ['diff_us_101[0][0]',            \n",
      "                                                                  'conv_mod_166[0][0]']           \n",
      "                                                                                                  \n",
      " conv_mod_171 (ConvMod)         (None, 512, 512, 32  28480       ['leaky_re_lu_124[0][0]',        \n",
      "                                )                                 'w6[0][0]']                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_49 (TFOpLambd  (None, 128, 128, 3)  0          ['add_192[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_125 (Lambda)            (None, 512, 512, 1)  0           ['noiseInp[0][0]',               \n",
      "                                                                  'conv_mod_171[0][0]']           \n",
      "                                                                                                  \n",
      " diff_us_103 (DiffUS)           (None, 256, 256, 3)  0           ['tf.math.multiply_49[0][0]']    \n",
      "                                                                                                  \n",
      " conv_mod_169 (ConvMod)         (None, 256, 256, 3)  87583       ['leaky_re_lu_123[0][0]',        \n",
      "                                                                  'w5[0][0]']                     \n",
      "                                                                                                  \n",
      " fce_358 (FCE)                  (None, 512, 512, 32  32          ['lambda_125[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_195 (Add)                  (None, 256, 256, 3)  0           ['diff_us_103[0][0]',            \n",
      "                                                                  'conv_mod_169[0][0]']           \n",
      "                                                                                                  \n",
      " add_197 (Add)                  (None, 512, 512, 32  0           ['conv_mod_171[0][0]',           \n",
      "                                )                                 'fce_358[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply_50 (TFOpLambd  (None, 256, 256, 3)  0          ['add_195[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_125 (LeakyReLU)    (None, 512, 512, 32  0           ['add_197[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " diff_us_105 (DiffUS)           (None, 512, 512, 3)  0           ['tf.math.multiply_50[0][0]']    \n",
      "                                                                                                  \n",
      " conv_mod_172 (ConvMod)         (None, 512, 512, 3)  19331       ['leaky_re_lu_125[0][0]',        \n",
      "                                                                  'w6[0][0]']                     \n",
      "                                                                                                  \n",
      " add_198 (Add)                  (None, 512, 512, 3)  0           ['diff_us_105[0][0]',            \n",
      "                                                                  'conv_mod_172[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.multiply_51 (TFOpLambd  (None, 512, 512, 3)  0          ['add_198[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " cve_290 (CVE)                  (None, 512, 512, 3)  12          ['tf.math.multiply_51[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,924,547\n",
      "Trainable params: 23,924,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3 * batchSize / 32\n",
    "mapOpt = Adam(lr / 100, epsilon=1e-8)\n",
    "genOpt = Adam(lr, 0, 0.9, epsilon=1e-8)\n",
    "discOpt = Adam(lr, 0, 0.9, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt(truePreds): # overfitting metric\n",
    "    return tf.reduce_mean(tf.sign(truePreds))\n",
    "\n",
    "def dra(obsPreds, basePreds): # observe/baseline predictions (representing fake/true data)\n",
    "    meanBase = K.mean(basePreds)\n",
    "    return tf.nn.sigmoid(obsPreds - meanBase)\n",
    "\n",
    "def discLoss(truePreds, fakePreds, epsilon=eps):\n",
    "    trueLoss = K.mean(tf.nn.softplus(-truePreds)) # -log(sigmoid(real_scores_out))\n",
    "    fakeLoss = K.mean(tf.nn.softplus(fakePreds)) # -log(1-sigmoid(fake_scores_out))\n",
    "    classLoss = trueLoss + fakeLoss\n",
    "    return classLoss\n",
    "\n",
    "def genLoss(fakePreds, epsilon=eps):\n",
    "    classLoss = K.mean(tf.nn.softplus(-fakePreds))\n",
    "    return classLoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path length reg.\n",
    "@tf.function\n",
    "def pplReg(a=0.0):\n",
    "    pplbatchSize = batchSize // 2\n",
    "    y = tf.random.normal((pplbatchSize, imgSize, imgSize, 3))\n",
    "    noise = tf.random.uniform((pplbatchSize, imgSize, imgSize, 1))\n",
    "    z = tf.random.normal((pplbatchSize, zdim))\n",
    "    \n",
    "    w = mapper(z, training=True)\n",
    "    ws = [w for _ in range(nBlocks+1)]\n",
    "    preds = generator([*ws, noise], training=True)\n",
    "    jacLite = tf.math.reduce_sum(preds * y)\n",
    "    \n",
    "    jac = tf.gradients(jacLite, w)[0]\n",
    "    norm = tf.norm(jac)\n",
    "    return K.mean(tf.square(norm - tf.cast(a, tf.float32))), norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FID function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "allRealFeatures = None\n",
    "\n",
    "# turn TF tensor outputs into numpy array outputs\n",
    "def toNp(*args):\n",
    "    ret = []\n",
    "    for i in args:\n",
    "        meanVal = i\n",
    "        try:\n",
    "            meanVal = i.numpy()\n",
    "        except:\n",
    "            pass\n",
    "        ret.append(meanVal)\n",
    "    return ret\n",
    "\n",
    "def calculate_fid():\n",
    "    global allRealFeatures\n",
    "    \n",
    "    def crunch(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w2_range)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        realFeatures = inception(batch/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), realFeatures.numpy()\n",
    "    def crunchLite(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w1_range)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), -1\n",
    "    \n",
    "    K.clear_session()\n",
    "    bs = 16\n",
    "    expandM = bs * (m//bs)\n",
    "    crunchFunc = crunchLite\n",
    "    if allRealFeatures is None:\n",
    "        crunchFunc = crunch\n",
    "        allRealFeatures = np.zeros((expandM, 2048))\n",
    "        \n",
    "    allFakeFeatures = np.zeros((expandM, 2048))\n",
    "    for batchS in tqdm(range(0, expandM, bs)):\n",
    "        batch = reals[batchS: batchS + bs]\n",
    "        fakeFeatures, realFeatures = crunchFunc(batch, bs=bs)\n",
    "        allFakeFeatures[batchS: batchS + bs] = fakeFeatures\n",
    "        \n",
    "        if crunchFunc == crunch:\n",
    "            allRealFeatures[batchS: batchS + bs] = realFeatures\n",
    "        \n",
    "    # calculate mean and covariance statistics\n",
    "    fakeMean, fakeStd = np.mean(allFakeFeatures, axis=0), np.cov(allFakeFeatures, rowvar=False)\n",
    "    realMean, realStd = np.mean(allRealFeatures, axis=0), np.cov(allRealFeatures, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((fakeMean - realMean) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(np.dot(fakeStd, realStd))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(fakeStd + realStd - 2.0 * covmean)\n",
    "    K.clear_session()\n",
    "    return fid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "One training step for the GAN.\n",
    "Args:\n",
    "batch - input batch of real images\n",
    "p - probability of augmenting image\n",
    "pplEMA - skip PPL reg. if it is -1, else use the value for regularization\n",
    "useGP - skip R1 gradient penalty if it is -1\n",
    "'''\n",
    "@tf.function\n",
    "def trainStep(batch, p, pplEMA=-tf.ones(()), useGP=-tf.ones(())):\n",
    "    def genImgs():\n",
    "        z1 = tf.random.normal([batchSize, zdim])\n",
    "        z2 = tf.random.normal([batchSize, zdim])\n",
    "        noise = tf.random.normal([batchSize, imgSize, imgSize, 1])\n",
    "\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=True)\n",
    "        w2 = tf.cond(tf.random.uniform(()) < 0.9, lambda: mapper(z2, training=True), lambda: w1)\n",
    "        splitInd = npr.randint(nBlocks+1)\n",
    "        ws = [w1 for _ in range(splitInd)] + [w2 for _ in range(nBlocks+1-splitInd)]\n",
    "        fakes = generator([*ws, noise], training=True)\n",
    "        return fakes\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augBatch = aug(batch, p)\n",
    "    augFakes = aug(fakes, p)\n",
    "    truePreds = discriminator(augBatch, training=True)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    gpWeight = 16 * 10 / 2\n",
    "    gploss = tf.cond(useGP >= 0, lambda: gpWeight * K.mean((tf.reduce_sum(tf.square(tf.gradients(truePreds, [augBatch])[0]), axis=[1,2,3]))), lambda: 0.0)\n",
    "\n",
    "    dloss = discLoss(truePreds, fakePreds) + gploss\n",
    "    rtBatch = rt(truePreds)\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augFakes = aug(fakes, p)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    pplWeight = 8 * 2 / (imgSize * imgSize * (nBlocks + 1))\n",
    "    pplLoss, pplNorm = tf.cond(pplEMA >= 0, lambda: pplReg(pplEMA), lambda: (0.0, 0.0))\n",
    "    pplLoss = pplWeight * pplLoss\n",
    "    gloss = genLoss(fakePreds) + pplLoss\n",
    "    \n",
    "    dGrad = tf.gradients(dloss, discriminator.trainable_variables)\n",
    "    discOpt.apply_gradients(zip(dGrad, discriminator.trainable_variables))\n",
    "\n",
    "    gGrad = tf.gradients(gloss, generator.trainable_variables)\n",
    "    genOpt.apply_gradients(zip(gGrad, generator.trainable_variables))\n",
    "    \n",
    "    mGrad = tf.gradients(gloss, mapper.trainable_variables)\n",
    "    mapOpt.apply_gradients(zip(mGrad, mapper.trainable_variables))\n",
    "    \n",
    "    return dloss, gploss, gloss, rtBatch, pplLoss, pplNorm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retGrads():\n",
    "    z1 = tf.random.normal([1, zdim])\n",
    "    z2 = tf.random.normal([1, zdim])\n",
    "    noise = tf.random.normal([1, imgSize, imgSize, 1])\n",
    "    randImg = tf.convert_to_tensor(reals[npr.randint(0, reals.shape[0])][np.newaxis])\n",
    "\n",
    "    with tf.GradientTape() as tapeReal, tf.GradientTape() as tapeFake:\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "        tapeReal.watch(randImg)\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        tapeFake.watch(fakes)\n",
    "        truePreds = discriminator(randImg, training=False)\n",
    "        fakePreds = discriminator(fakes, training=False)\n",
    "        dloss = discLoss(truePreds, fakePreds)\n",
    "\n",
    "    realGrad = tapeReal.gradient(dloss, randImg)[0]\n",
    "    fakeGrad = tapeFake.gradient(dloss, fakes)[0]\n",
    "    realNorm = tf.norm(realGrad)\n",
    "    fakeNorm = tf.norm(fakeGrad)\n",
    "    return realGrad.numpy(), fakeGrad.numpy(), realNorm.numpy(), fakeNorm.numpy(), randImg[0].numpy(), fakes[0].numpy(), truePreds.numpy(), fakePreds.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=None, steps=None, n=4):\n",
    "    global p, pplNorms, pplEMA\n",
    "    gc.collect()\n",
    "    rtBatches = 0\n",
    "    \n",
    "    if epochs != None:\n",
    "        for i in range(epochs):\n",
    "            gc.collect()\n",
    "            dcost, gpcost, gcost = 0, 0, 0\n",
    "            pplSum = 0\n",
    "            rtSum, pplCost = 0, 0\n",
    "            batchNum = 0\n",
    "            for batch in ds:\n",
    "                pTensor = tf.convert_to_tensor(p, dtype=tf.float32)\n",
    "                batch = reals[npr.randint(0, m, (batchSize,))]\n",
    "                if batchNum % 16 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA), useGP=tf.ones(())))\n",
    "                elif batchNum % 8 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA)))\n",
    "                else:\n",
    "                    vals = toNp(*trainStep(batch, pTensor))\n",
    "                dloss, gploss, gloss, rtBatch, pplLoss, pplNorm = vals\n",
    "\n",
    "                if pplNorm != 0:\n",
    "                    pplEMA = 0.01 * pplNorm + 0.99 * pplEMA\n",
    "                \n",
    "                rtBatches += rtBatch\n",
    "                if batchNum % n == 0:\n",
    "                    p += pStep * np.sign(rtBatches/n - 0.6)\n",
    "                    p = round(min(max(p, 0), 1), 6) % 0.8\n",
    "                    rtBatches = 0\n",
    "                batchNum += 1\n",
    "                dcost += dloss; gpcost += gploss; gcost += gloss; rtSum += rtBatch; pplCost += pplLoss; pplSum += pplNorm\n",
    "            \n",
    "            dcosts.append(dcost)\n",
    "            gcosts.append(gcost)\n",
    "            gpcosts.append(gpcost)\n",
    "            pplNorms.append(round(pplSum / batchNum, 4))\n",
    "            ps.append(p)\n",
    "            rts.append(rtBatch)\n",
    "            print('Epoch: {} | D Cost: {} | GP Cost: {} | G Cost: {}'.format(i, dcost, gpcost, gcost), end = ' | ')\n",
    "            print('P(aug): {} | Rt: {} | PPL Norm: {} | PPL Loss: {}'.format(p, round(rtSum / batchNum, 4), round(pplSum / batchNum, 4), round(pplCost, 4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 4\n",
    "\n",
    "'''\n",
    "Display generated images as well as a summary of model metrics.\n",
    "Args:\n",
    "z1/z2 - latent input vector 1/2\n",
    "noise - noise input\n",
    "verbose - 5-element list saying which metrics to calculate and print out\n",
    "verbose[0] - FID score\n",
    "verbose[1] - D(G(z)) - discriminator predictions on generated images\n",
    "verbose[2] - D(x) - discriminator predictions on real images\n",
    "verbose[3/4] - D/G Loss\n",
    "verbose=True/1: print everything\n",
    "verbose=False/0: print nothing\n",
    "'''\n",
    "\n",
    "def display(z1, z2, noise, verbose=True):\n",
    "    gc.collect()\n",
    "    fig = plt.figure(figsize=(30, 5))\n",
    "    axes = fig.subplots(rows, cols)\n",
    "    \n",
    "    z1[0] = constZ; z2[0] = constZ; noise[0] = constNoise\n",
    "    assert z1.shape == (rows * cols, zdim)\n",
    "    assert z2.shape == (rows * cols, zdim)\n",
    "    assert noise.shape == (rows * cols, imgSize, imgSize, 1)\n",
    "        \n",
    "    randInds = npr.randint(0, reals.shape[0], (rows*cols,))\n",
    "    \n",
    "    w1 = z1; w2 = z2\n",
    "    w1 = mapper(z1, training=False)\n",
    "    w2 = mapper(z2, training=False)\n",
    "    ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w2_range)]\n",
    "    preds = generator([*ws, noise], training=False)\n",
    "    df = discriminator(preds, training=False)\n",
    "    dr = discriminator(reals[randInds], training=False)\n",
    "    if type(verbose) == type(True):\n",
    "        verbose = [verbose for i in range(5)]\n",
    "    if type(verbose) == int:\n",
    "        if verbose == 0:\n",
    "            verbose = [False for i in range(5)]\n",
    "        elif verbose == 1:\n",
    "            verbose = [False, False, False, True, True]\n",
    "        elif verbose == 2:\n",
    "            verbose = [False, True, True, True, True]\n",
    "        elif verbose == 3:\n",
    "            verbose = [True for i in range(5)]\n",
    "            \n",
    "    if verbose[1]:\n",
    "        print('D(G(z)) (lower = better disc):', np.mean(df))\n",
    "    if verbose[2]:\n",
    "        print('D(x) (higher = better disc):', np.mean(dr))\n",
    "    if verbose[3]:\n",
    "        print('D Loss:', discLoss(dr, df))\n",
    "    if verbose[4]:\n",
    "        print('G Loss:', genLoss(df))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[j].imshow(preds[i*cols + j] / 2 + 0.5)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if verbose[0]:\n",
    "        fid = round(calculate_fid(), 4)\n",
    "        print('FID:', fid)\n",
    "        fids.append(fid)\n",
    "    return preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save current state of model, overwriting past state of model on disk.\n",
    "Args:\n",
    "askInp - require user to place input before saving models - protects user from accidentally overwriting models with a collapsed model\n",
    "'''\n",
    "def save_models(askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    \n",
    "    \n",
    "    generator.save_weights(modelPath+'genWeights.h5')\n",
    "    discriminator.save_weights(modelPath+'discWeights.h5')\n",
    "    mapper.save_weights(modelPath+'mapWeights.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:37:42.233814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-04-11 16:37:42.247519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"discriminator\" is incompatible with the layer: expected shape=(None, 600, 600, 3), found shape=(4, 512, 512, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     sess \u001b[38;5;241m=\u001b[39m timeIt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     train(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     10\u001b[0m     epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(z1, z2, noise, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m ws \u001b[38;5;241m=\u001b[39m [w1 \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w1_range)] \u001b[38;5;241m+\u001b[39m [w2 \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w2_range)]\n\u001b[1;32m     33\u001b[0m preds \u001b[38;5;241m=\u001b[39m generator([\u001b[38;5;241m*\u001b[39mws, noise], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m dr \u001b[38;5;241m=\u001b[39m discriminator(reals[randInds], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(verbose) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/keras/engine/input_spec.py:298\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 298\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"discriminator\" is incompatible with the layer: expected shape=(None, 600, 600, 3), found shape=(4, 512, 512, 3)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "constZ = npr.randn(zdim,)\n",
    "constNoise = npr.randn(imgSize, imgSize, 1)\n",
    "epoch = 0\n",
    "if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "        loadData()\n",
    "while True:\n",
    "    sess = timeIt('Training')\n",
    "    display(z1=npr.randn(rows * cols, zdim), z2=npr.randn(rows * cols, zdim), noise=npr.randn(rows * cols, imgSize, imgSize, 1), verbose=True)\n",
    "    train(epochs=50)\n",
    "    epoch += 1\n",
    "    sess.close()\n",
    "    save_models(askInp=False)\n",
    "    np.save(os.path.join(modelPath, 'p.npy'), p) # save p value for future training if training on servers with time limits like Paperspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "    #loadData()\n",
    "    reals = np.load(os.path.join(datasetPath, 'imgs.npy'))\n",
    "    m = batchSize * (reals.shape[0] // batchSize)\n",
    "    reals = reals[:m].astype(np.float32)\n",
    "\n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(tf.cast(reals, tf.float32)).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "\n",
    "dGrad, gGrad, dNorm, gNorm, img, fake, truePreds, fakePreds = retGrads()\n",
    "dGrad = np.sum(dGrad, axis=2)\n",
    "gGrad = np.sum(gGrad, axis=2)\n",
    "print('D(x): {} | D(G(z)): {}'.format(truePreds, fakePreds))\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "dGrad = (dGrad - np.min(dGrad)) / (np.max(dGrad) - np.min(dGrad) + eps)\n",
    "gGrad = (gGrad - np.min(gGrad)) / (np.max(gGrad) - np.min(gGrad) + eps)\n",
    "axes[0][0].imshow(img/2+0.5)\n",
    "axes[0][1].imshow(fake/2+0.5)\n",
    "axes[1][0].imshow(dGrad)\n",
    "axes[1][0].set_title('Real Grad; Norm: {}'.format(round(dNorm, 4)))\n",
    "axes[1][1].imshow(gGrad)\n",
    "axes[1][1].set_title('Fake Grad; Norm: {}'.format(round(gNorm, 4)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize mapping activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = npr.randn(1, zdim)\n",
    "w = mapper.predict(z)\n",
    "plt.imshow(z[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(w[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    constZ1s\n",
    "except Exception as e:\n",
    "    constZ1s = npr.randn(rows*cols, zdim)\n",
    "    constZ2s = npr.randn(rows*cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "\n",
    "'''\n",
    "if z1s commented out, same content, different styles\n",
    "if z2s commented out, different content, same styles\n",
    "if noise = 0, undesirably smooth faces but just a test to make sure styles are working properly\n",
    "'''\n",
    "for i in range(1): \n",
    "    constZ1s = npr.randn(rows * cols, zdim)\n",
    "    #constZ2s = npr.randn(rows * cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1) * 0\n",
    "    pred11=display(z1=constZ1s, z2=constZ2s, noise=constNoises, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    constZ1s\n",
    "except Exception as e:\n",
    "    constZ1s = npr.randn(rows*cols, zdim)\n",
    "    constZ2s = npr.randn(rows*cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "    \n",
    "fig, axes = plt.subplots(nrows=2, ncols=cols, figsize=(30, 15))\n",
    "\n",
    "z1 = constZ1s; z2 = constZ2s; noise = constNoises\n",
    "\n",
    "randInds = npr.randint(0, reals.shape[0], (rows*cols,))\n",
    "\n",
    "w1 = z1; w2 = z2\n",
    "ws = [w1 for i in range(3)] + [w2 for i in range(4)]\n",
    "preds = generator([*ws, noise], training=False)\n",
    "\n",
    "for i in range(cols):\n",
    "    axes[0][i].imshow(preds[i] / 2 + 0.5)\n",
    "    \n",
    "w1 = mapper(z1, training=False)\n",
    "w2 = mapper(z2, training=False)\n",
    "ws = [w1 for i in range(3)] + [w2 for i in range(4)]\n",
    "preds = generator([*ws, noise], training=False)\n",
    "\n",
    "for i in range(cols):\n",
    "    axes[1][i].imshow(preds[i] / 2 + 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See metrics over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "pltX = range(len(dcosts))\n",
    "axes[0].plot(pltX, dcosts); axes[0].set_title('D Loss')\n",
    "axes[1].plot(pltX, gcosts); axes[1].set_title('G Loss')\n",
    "axes[2].plot(pltX, gpcosts); axes[2].set_title('GP')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n",
    "axes[0].plot(pltX, ps); axes[0].set_title('Evolution of P(aug) over training')\n",
    "axes[1].plot(pltX, rts); axes[1].set_title('Evolution of r_t')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n",
    "axes.set_title('D Loss (Blue) vs. G Loss (Orange)')\n",
    "axes.plot(pltX, dcosts, color='blue')\n",
    "axes.plot(pltX, gcosts, color='orange')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
