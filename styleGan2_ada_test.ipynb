{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 13:20:21.171823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 13:20:21.885719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/gil/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy.random as npr\n",
    "import os, time, gc, random\n",
    "import glob\n",
    "import PIL\n",
    "from tqdm.auto import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks used in GAN\n",
    "\n",
    "def minibatchStd(inputs):\n",
    "    inputs = tf.transpose(inputs, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "    group_size = tf.minimum(4, tf.shape(inputs)[0])             # Minibatch must be divisible by (or smaller than) group_size.\n",
    "    s = inputs.shape                                             # [NCHW]  Input shape.\n",
    "    y = tf.reshape(inputs, [group_size, -1, 1, s[1], s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
    "    y -= tf.reduce_mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n",
    "    y = tf.reduce_mean(tf.square(y), axis=0)                # [MncHW]  Calc variance over group.\n",
    "    y = tf.sqrt(y + eps)                                    # [MncHW]  Calc stddev over group.\n",
    "    y = tf.reduce_mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n",
    "    y = tf.reduce_mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n",
    "    y = tf.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n",
    "    y = tf.concat([inputs, y], axis=1)                        # [NCHW]  Append as new fmap.\n",
    "    y = tf.transpose(y, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "    return y\n",
    "\n",
    "class DiffUS(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        return super().__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        _N, H, W, C = inputs.shape.as_list()\n",
    "        x = K.reshape(inputs, (-1, H, 1, W, 1, C))\n",
    "        x = tf.tile(x, (1, 1, 2, 1, 2, 1))\n",
    "        used = K.reshape(x, (-1, H * 2, W * 2, C))\n",
    "        return used\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    noise, img = x\n",
    "    height = img.shape[1]\n",
    "    width = img.shape[2]\n",
    "    \n",
    "    return noise[:, :height, :width, :]\n",
    "\n",
    "ndist = tf.random_normal_initializer(0, 1)\n",
    "zeros = tf.zeros_initializer()\n",
    "ones = tf.ones_initializer()\n",
    "\n",
    "class FCE(Dense): # fully connected equalized\n",
    "    def __init__(self, units, kernel_initializer=ndist, bias_initializer=zeros, lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('fce', input_shape)\n",
    "        n = input_shape[-1] # input_shape = (None, features_in) or (None, dimY, dimX, features_in)\n",
    "        if self.lrelu:\n",
    "            self.scale = np.sqrt((1 / 0.6) / n) # he but not really, 1 / 0.6 since lrelu(0.2) makes scales variance to 0.6 (0.2 if neg, 1 if pos, div by 2) and you want them to be 1\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.dot(inputs, self.kernel * self.scale)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class CVE(Conv2D):\n",
    "    def __init__(self, units, kernel_size=3, kernel_initializer=ndist, bias_initializer=zeros, padding='same', lrelu=True, *args, **kwargs):\n",
    "        super().__init__(units, kernel_size, *args, **kwargs)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.padding = padding\n",
    "        self.lrelu = lrelu\n",
    "        self.scale = 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        #print('cve', self.kernel.shape)\n",
    "        n = np.prod(self.kernel.shape[:-1]) # self.kernel.shape = (kernel_x, kernel_y, features_in, features_out)\n",
    "        if self.lrelu: # he\n",
    "            self.scale = np.sqrt((1 / 0.6) / n)\n",
    "        else:\n",
    "            self.scale = np.sqrt(1 / n)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = K.conv2d(inputs, self.kernel * self.scale, padding=self.padding)\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias)\n",
    "        if self.activation is not tf.keras.activations.linear:\n",
    "            output = self.activation(output)\n",
    "        elif self.lrelu:\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'kInit': self.kernel_initializer,\n",
    "            'bInit': self.bias_initializer,\n",
    "            'padding': self.padding,\n",
    "            'scale': self.scale,\n",
    "            'useLReLU': self.lrelu,\n",
    "                      })\n",
    "        return config\n",
    "\n",
    "class ConvMod(Layer):\n",
    "    def __init__(self, nf, x, w, kSize=3, demod=True):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        self.kSize = kSize\n",
    "        self.xShape = x.shape\n",
    "        self.wShape = w.shape\n",
    "        self.scale = FCE(self.xShape[-1], bias_initializer=ones, lrelu=False)\n",
    "        self.conv = CVE(nf, kSize, lrelu=demod)\n",
    "        self.conv(x) # create kernel without doing it in build method so h5py doesn't go sicko mode\n",
    "        self.demod = demod\n",
    "\n",
    "    def build(self, input_shape): # input_shape: [TensorShape([None, 4, 4, 256]), TensorShape([None, 256]), TensorShape([None, 4, 4, 1])]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "\n",
    "        x = tf.transpose(x, (0, 3, 1, 2)) # NHWC -> NCHW\n",
    "        weight = self.conv.kernel[np.newaxis] * self.conv.scale # kkio -> 1kkio (1, kernel_size, kernel_size, input_features, output_features)\n",
    "\n",
    "        scale = self.scale(w)\n",
    "        scale = scale[:, np.newaxis, np.newaxis, :, np.newaxis] # Bs -> B, 1, 1, s, 1 (s - scaling factor)\n",
    "\n",
    "        wp = weight * scale # 1kkio * B11s1 -> Bkk(s*i)o\n",
    "        wpp = wp\n",
    "\n",
    "        if self.demod:\n",
    "            wStd = tf.math.rsqrt(tf.reduce_sum(tf.math.square(wp), axis=[1,2,3]) + 1e-8) # Bkkio -> Bo\n",
    "            wpp = wp * wStd[:, np.newaxis, np.newaxis, np.newaxis, :] # [BkkIO] Scale output feature maps.\n",
    "\n",
    "        x = tf.reshape(x, (1, -1, x.shape[2], x.shape[3])) # N, C, H, W -> 1, (N*C), H, W\n",
    "\n",
    "        # B, k, k, i, o -> k, k, i, B, o -> k, k, i, (B*o)\n",
    "        wpp = tf.reshape(tf.transpose(wpp, [1, 2, 3, 0, 4]), [wpp.shape[1], wpp.shape[2], wpp.shape[3], -1])\n",
    "\n",
    "        x = tf.nn.conv2d(x, wpp, padding='SAME', data_format='NCHW', strides=[1, 1, 1, 1]) # grouped conv\n",
    "        x = tf.reshape(x, (-1, self.nf, x.shape[2], x.shape[3])) # 1, (N*C), H, W -> N, C, H, W\n",
    "        x = tf.transpose(x, (0, 2, 3, 1)) # NCHW -> NHWC\n",
    "        x = K.bias_add(x, self.conv.bias)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'num_filters': self.nf,\n",
    "            'kernel_size': self.kSize,\n",
    "            'xShape': self.xShape,\n",
    "            'wShape': self.wShape,\n",
    "            'demodulated': self.demod\n",
    "                      })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing timer; 0.0052 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "# custom class to see how long tasks take\n",
    "class timeIt:\n",
    "    def __init__(self, description):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        self.running = True\n",
    "    \n",
    "    def new(self, description, verbose=True):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        \n",
    "        duration = time.time() - startTime\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "        \n",
    "        return duration\n",
    "    \n",
    "    def close(self, verbose=True):\n",
    "        duration = time.time() - self.start\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "            \n",
    "        self.start = None\n",
    "        self.description = None\n",
    "        self.running = False\n",
    "        return duration\n",
    "\n",
    "sess = timeIt('testing timer')\n",
    "time.sleep(0.005)\n",
    "_ = sess.close(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reals - numpy array of the training images; ds - batched TF dataset given to the GPU\n",
    "datasetPath = '../../data/brca_tile_1024/*.png'\n",
    "modelPath = '../../model/styleGAN2/brca/1024/'\n",
    "reals, ds = None, None\n",
    "gc.collect()\n",
    "\n",
    "batchSize = 4\n",
    "m = 2000 # amount of images stored in RAM (reduce if low RAM, increase if high RAM)\n",
    "m = min(m, int(len(glob.glob(datasetPath))))\n",
    "\n",
    "m = batchSize * (m // batchSize)\n",
    "imgSize =512# size of images in pixels\n",
    "zdim = imgSize # number of elements in a latent vector\n",
    "p = 0.0 # probability of data augmentation\n",
    "n = 4 # number of minibatches before p is changed\n",
    "numImgsStep = 5e5 # number of images needed to change p from 0 -> 1 or 1 -> 0\n",
    "pStep = n * batchSize / numImgsStep # how much p increases/decreases per n minibatches\n",
    "eps = 1e-8 # epsilon, small number used to prevent NaN errors\n",
    "pplEMA = 0.0 # exponential moving average for average PPL for PPL reg.\n",
    "discLayerFilters = np.linspace(32,imgSize,int(np.log2(imgSize/4)),dtype=np.int32)\n",
    "genLayerFilters = np.linspace(imgSize,32,int(np.log2(imgSize/4)),dtype=np.int32)\n",
    "w1_range=int(np.log2(imgSize/2)/2)\n",
    "w2_range=int(np.log2(imgSize/2)/2+(np.log2(imgSize/2)%2>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generator style block.\n",
    "Args:\n",
    "accum - accumulated output from the input/output skips\n",
    "x - the non-RGB image input\n",
    "w - the style (output of the mapping function with input of the latent vector)\n",
    "noiseInp - normally distributed noise\n",
    "filters - number of channels/feature maps the output of the style block will have\n",
    "us - whether or not to upsample the images\n",
    "'''\n",
    "def gblock(accum, x, w, noiseInp, filters, us=True):\n",
    "    if us:\n",
    "        x = DiffUS()(x) # using custom upsampling function since other upsampling methods didn't provide gradients of their gradients\n",
    "        accum = DiffUS()(accum)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = ConvMod(filters, x, w)([x, w])\n",
    "        noise = Lambda(crop_to_fit)([noiseInp, x]) # crop noises so it can be added with x\n",
    "        noise = FCE(filters, kernel_initializer=zeros, use_bias=False, lrelu=False)(noise) #scale noises\n",
    "        x = Add()([x, noise])\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    trgb = ConvMod(3, x, w, 1, demod=False)([x, w]) # toRGB 1x1 convolution\n",
    "    accum = Add()([accum, trgb]) * np.sqrt(1 / 2) # the sqrt(1/2) not included in original StyleGAN2 but i didn't see why not\n",
    "        \n",
    "    return accum, x\n",
    "\n",
    "# Discriminator block.\n",
    "def dblock(x, filters, maxFilters=256):\n",
    "    frgb = CVE(min(2 * filters, maxFilters), 1, lrelu=False, use_bias=False)(x)\n",
    "    \n",
    "    x = CVE(filters)(x)\n",
    "    x = CVE(min(2 * filters, maxFilters))(x)\n",
    "        \n",
    "    frgb = AveragePooling2D()(frgb)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Add()([x, frgb])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBlocks = int(np.log2(imgSize / 4)) # number of upsampled style blocks\n",
    "\n",
    "# mapper architecture\n",
    "def ztow(nlayers=8):\n",
    "    z = Input((zdim,))\n",
    "    w = z\n",
    "    if nlayers > 0:\n",
    "        w = LayerNormalization()(w)\n",
    "    for i in range(max(nlayers-1, 0)):\n",
    "        w = FCE(zdim)(w)\n",
    "    return Model(z, w, name='mapping')\n",
    "\n",
    "# generator architecture\n",
    "def genGen():\n",
    "    ws = [Input((zdim,), name='w{}'.format(i)) for i in range(nBlocks+1)]\n",
    "    noiseInp = Input((imgSize, imgSize, 1), name='noiseInp')\n",
    "\n",
    "    x = Dense(1)(ws[0]); x = Lambda(lambda x: x * 0 + 1)(x)\n",
    "    x = FCE(4*4*zdim, lrelu=False, use_bias=False)(x)\n",
    "    x = Reshape((4, 4, zdim))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = ConvMod(genLayerFilters[0], x, ws[0])([x, ws[0]])\n",
    "    noise = Lambda(crop_to_fit)([noiseInp, x])\n",
    "    noise = FCE(genLayerFilters[0], kernel_initializer=zeros, use_bias=False, lrelu=False)(noise)\n",
    "    x = Add()([x, noise])\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    accum = ConvMod(3, x, ws[0], 1, demod=False)([x, ws[0]])\n",
    "    \n",
    "    for idx, f in enumerate(genLayerFilters):\n",
    "        accum, x = gblock(accum, x, ws[idx+1], noiseInp, f)\n",
    "        \n",
    "    out = CVE(3, 1, lrelu=False)(accum)\n",
    "    return Model([*ws, noiseInp], out, name='generator')\n",
    "      \n",
    "# discriminator architecture  \n",
    "def genDisc():\n",
    "    inp = Input((imgSize, imgSize, 3)); x = inp\n",
    "\n",
    "    \n",
    "    x = CVE(discLayerFilters[0], 1)(x)\n",
    "    for fi, f in enumerate(discLayerFilters):\n",
    "        x = dblock(x, f, maxFilters=discLayerFilters[-1])\n",
    "    \n",
    "    x = Lambda(minibatchStd)(x)\n",
    "    x = CVE(discLayerFilters[-1])(x)\n",
    "    x = Flatten()(x)\n",
    "    x = FCE(discLayerFilters[-1])(x)\n",
    "    out = FCE(1, lrelu=False)(x)\n",
    "\n",
    "    return Model(inp, out, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 13:20:24.096231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38374 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:e1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "fids, gcosts, dcosts = [], [], []\n",
    "pplNorms = []\n",
    "gpcosts = []\n",
    "ps, rts = [], []\n",
    "\n",
    "\n",
    "mapper = ztow()\n",
    "generator = genGen()\n",
    "discriminator = genDisc()\n",
    "inception = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(imgSize, imgSize, 3)) # for FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3 * batchSize / 32\n",
    "mapOpt = Adam(lr / 100, epsilon=1e-8)\n",
    "genOpt = Adam(lr, 0, 0.9, epsilon=1e-8)\n",
    "discOpt = Adam(lr, 0, 0.9, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt(truePreds): # overfitting metric\n",
    "    return tf.reduce_mean(tf.sign(truePreds))\n",
    "\n",
    "def dra(obsPreds, basePreds): # observe/baseline predictions (representing fake/true data)\n",
    "    meanBase = K.mean(basePreds)\n",
    "    return tf.nn.sigmoid(obsPreds - meanBase)\n",
    "\n",
    "def discLoss(truePreds, fakePreds, epsilon=eps):\n",
    "    trueLoss = K.mean(tf.nn.softplus(-truePreds)) # -log(sigmoid(real_scores_out))\n",
    "    fakeLoss = K.mean(tf.nn.softplus(fakePreds)) # -log(1-sigmoid(fake_scores_out))\n",
    "    classLoss = trueLoss + fakeLoss\n",
    "    return classLoss\n",
    "\n",
    "def genLoss(fakePreds, epsilon=eps):\n",
    "    classLoss = K.mean(tf.nn.softplus(-fakePreds))\n",
    "    return classLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path length reg.\n",
    "@tf.function\n",
    "def pplReg(a=0.0):\n",
    "    pplbatchSize = batchSize // 2\n",
    "    y = tf.random.normal((pplbatchSize, imgSize, imgSize, 3))\n",
    "    noise = tf.random.uniform((pplbatchSize, imgSize, imgSize, 1))\n",
    "    z = tf.random.normal((pplbatchSize, zdim))\n",
    "    \n",
    "    w = mapper(z, training=True)\n",
    "    ws = [w for _ in range(nBlocks+1)]\n",
    "    preds = generator([*ws, noise], training=True)\n",
    "    jacLite = tf.math.reduce_sum(preds * y)\n",
    "    \n",
    "    jac = tf.gradients(jacLite, w)[0]\n",
    "    norm = tf.norm(jac)\n",
    "    return K.mean(tf.square(norm - tf.cast(a, tf.float32))), norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "allRealFeatures = None\n",
    "\n",
    "# turn TF tensor outputs into numpy array outputs\n",
    "def toNp(*args):\n",
    "    ret = []\n",
    "    for i in args:\n",
    "        meanVal = i\n",
    "        try:\n",
    "            meanVal = i.numpy()\n",
    "        except:\n",
    "            pass\n",
    "        ret.append(meanVal)\n",
    "    return ret\n",
    "\n",
    "def calculate_fid():\n",
    "    global allRealFeatures\n",
    "    \n",
    "    def crunch(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w2_range)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        realFeatures = inception(batch/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), realFeatures.numpy()\n",
    "    def crunchLite(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w1_range)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), -1\n",
    "    \n",
    "    K.clear_session()\n",
    "    bs = 16\n",
    "    expandM = bs * (m//bs)\n",
    "    crunchFunc = crunchLite\n",
    "    if allRealFeatures is None:\n",
    "        crunchFunc = crunch\n",
    "        allRealFeatures = np.zeros((expandM, 2048))\n",
    "        \n",
    "    allFakeFeatures = np.zeros((expandM, 2048))\n",
    "    for batchS in tqdm(range(0, expandM, bs)):\n",
    "        batch = reals[batchS: batchS + bs]\n",
    "        fakeFeatures, realFeatures = crunchFunc(batch, bs=bs)\n",
    "        allFakeFeatures[batchS: batchS + bs] = fakeFeatures\n",
    "        \n",
    "        if crunchFunc == crunch:\n",
    "            allRealFeatures[batchS: batchS + bs] = realFeatures\n",
    "        \n",
    "    # calculate mean and covariance statistics\n",
    "    fakeMean, fakeStd = np.mean(allFakeFeatures, axis=0), np.cov(allFakeFeatures, rowvar=False)\n",
    "    realMean, realStd = np.mean(allRealFeatures, axis=0), np.cov(allRealFeatures, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((fakeMean - realMean) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(np.dot(fakeStd, realStd))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(fakeStd + realStd - 2.0 * covmean)\n",
    "    K.clear_session()\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "One training step for the GAN.\n",
    "Args:\n",
    "batch - input batch of real images\n",
    "p - probability of augmenting image\n",
    "pplEMA - skip PPL reg. if it is -1, else use the value for regularization\n",
    "useGP - skip R1 gradient penalty if it is -1\n",
    "'''\n",
    "@tf.function\n",
    "def trainStep(batch, p, pplEMA=-tf.ones(()), useGP=-tf.ones(())):\n",
    "    def genImgs():\n",
    "        z1 = tf.random.normal([batchSize, zdim])\n",
    "        z2 = tf.random.normal([batchSize, zdim])\n",
    "        noise = tf.random.normal([batchSize, imgSize, imgSize, 1])\n",
    "\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=True)\n",
    "        w2 = tf.cond(tf.random.uniform(()) < 0.9, lambda: mapper(z2, training=True), lambda: w1)\n",
    "        splitInd = npr.randint(nBlocks+1)\n",
    "        ws = [w1 for _ in range(splitInd)] + [w2 for _ in range(nBlocks+1-splitInd)]\n",
    "        fakes = generator([*ws, noise], training=True)\n",
    "        return fakes\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augBatch = aug(batch, p)\n",
    "    augFakes = aug(fakes, p)\n",
    "    truePreds = discriminator(augBatch, training=True)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    gpWeight = 16 * 10 / 2\n",
    "    gploss = tf.cond(useGP >= 0, lambda: gpWeight * K.mean((tf.reduce_sum(tf.square(tf.gradients(truePreds, [augBatch])[0]), axis=[1,2,3]))), lambda: 0.0)\n",
    "\n",
    "    dloss = discLoss(truePreds, fakePreds) + gploss\n",
    "    rtBatch = rt(truePreds)\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augFakes = aug(fakes, p)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    pplWeight = 8 * 2 / (imgSize * imgSize * (nBlocks + 1))\n",
    "    pplLoss, pplNorm = tf.cond(pplEMA >= 0, lambda: pplReg(pplEMA), lambda: (0.0, 0.0))\n",
    "    pplLoss = pplWeight * pplLoss\n",
    "    gloss = genLoss(fakePreds) + pplLoss\n",
    "    \n",
    "    dGrad = tf.gradients(dloss, discriminator.trainable_variables)\n",
    "    discOpt.apply_gradients(zip(dGrad, discriminator.trainable_variables))\n",
    "\n",
    "    gGrad = tf.gradients(gloss, generator.trainable_variables)\n",
    "    genOpt.apply_gradients(zip(gGrad, generator.trainable_variables))\n",
    "    \n",
    "    mGrad = tf.gradients(gloss, mapper.trainable_variables)\n",
    "    mapOpt.apply_gradients(zip(mGrad, mapper.trainable_variables))\n",
    "    \n",
    "    return dloss, gploss, gloss, rtBatch, pplLoss, pplNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retGrads():\n",
    "    z1 = tf.random.normal([1, zdim])\n",
    "    z2 = tf.random.normal([1, zdim])\n",
    "    noise = tf.random.normal([1, imgSize, imgSize, 1])\n",
    "    randImg = tf.convert_to_tensor(reals[npr.randint(0, reals.shape[0])][np.newaxis])\n",
    "\n",
    "    with tf.GradientTape() as tapeReal, tf.GradientTape() as tapeFake:\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "        tapeReal.watch(randImg)\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        tapeFake.watch(fakes)\n",
    "        truePreds = discriminator(randImg, training=False)\n",
    "        fakePreds = discriminator(fakes, training=False)\n",
    "        dloss = discLoss(truePreds, fakePreds)\n",
    "\n",
    "    realGrad = tapeReal.gradient(dloss, randImg)[0]\n",
    "    fakeGrad = tapeFake.gradient(dloss, fakes)[0]\n",
    "    realNorm = tf.norm(realGrad)\n",
    "    fakeNorm = tf.norm(fakeGrad)\n",
    "    return realGrad.numpy(), fakeGrad.numpy(), realNorm.numpy(), fakeNorm.numpy(), randImg[0].numpy(), fakes[0].numpy(), truePreds.numpy(), fakePreds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=None, steps=None, n=4):\n",
    "    global p, pplNorms, pplEMA\n",
    "    gc.collect()\n",
    "    rtBatches = 0\n",
    "    \n",
    "    if epochs != None:\n",
    "        for i in range(epochs):\n",
    "            gc.collect()\n",
    "            dcost, gpcost, gcost = 0, 0, 0\n",
    "            pplSum = 0\n",
    "            rtSum, pplCost = 0, 0\n",
    "            batchNum = 0\n",
    "            for batch in ds:\n",
    "                pTensor = tf.convert_to_tensor(p, dtype=tf.float32)\n",
    "                batch = reals[npr.randint(0, m, (batchSize,))]\n",
    "                if batchNum % 16 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA), useGP=tf.ones(())))\n",
    "                elif batchNum % 8 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA)))\n",
    "                else:\n",
    "                    vals = toNp(*trainStep(batch, pTensor))\n",
    "                dloss, gploss, gloss, rtBatch, pplLoss, pplNorm = vals\n",
    "\n",
    "                if pplNorm != 0:\n",
    "                    pplEMA = 0.01 * pplNorm + 0.99 * pplEMA\n",
    "                \n",
    "                rtBatches += rtBatch\n",
    "                if batchNum % n == 0:\n",
    "                    p += pStep * np.sign(rtBatches/n - 0.6)\n",
    "                    p = round(min(max(p, 0), 1), 6) % 0.8\n",
    "                    rtBatches = 0\n",
    "                batchNum += 1\n",
    "                dcost += dloss; gpcost += gploss; gcost += gloss; rtSum += rtBatch; pplCost += pplLoss; pplSum += pplNorm\n",
    "            \n",
    "            dcosts.append(dcost)\n",
    "            gcosts.append(gcost)\n",
    "            gpcosts.append(gpcost)\n",
    "            pplNorms.append(round(pplSum / batchNum, 4))\n",
    "            ps.append(p)\n",
    "            rts.append(rtBatch)\n",
    "            print('Epoch: {} | D Cost: {} | GP Cost: {} | G Cost: {}'.format(i, dcost, gpcost, gcost), end = ' | ')\n",
    "            print('P(aug): {} | Rt: {} | PPL Norm: {} | PPL Loss: {}'.format(p, round(rtSum / batchNum, 4), round(pplSum / batchNum, 4), round(pplCost, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 1, 4\n",
    "\n",
    "'''\n",
    "Display generated images as well as a summary of model metrics.\n",
    "Args:\n",
    "z1/z2 - latent input vector 1/2\n",
    "noise - noise input\n",
    "verbose - 5-element list saying which metrics to calculate and print out\n",
    "verbose[0] - FID score\n",
    "verbose[1] - D(G(z)) - discriminator predictions on generated images\n",
    "verbose[2] - D(x) - discriminator predictions on real images\n",
    "verbose[3/4] - D/G Loss\n",
    "verbose=True/1: print everything\n",
    "verbose=False/0: print nothing\n",
    "'''\n",
    "\n",
    "def display(z1, z2, noise, verbose=True):\n",
    "    gc.collect()\n",
    "    fig = plt.figure(figsize=(30, 5))\n",
    "    axes = fig.subplots(rows, cols)\n",
    "    \n",
    "    z1[0] = constZ; z2[0] = constZ; noise[0] = constNoise\n",
    "    assert z1.shape == (rows * cols, zdim)\n",
    "    assert z2.shape == (rows * cols, zdim)\n",
    "    assert noise.shape == (rows * cols, imgSize, imgSize, 1)\n",
    "        \n",
    "    randInds = npr.randint(0, 512, (rows*cols,))\n",
    "    \n",
    "    w1 = z1; w2 = z2\n",
    "    w1 = mapper(z1, training=False)\n",
    "    w2 = mapper(z2, training=False)\n",
    "    ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w2_range)]\n",
    "    preds = generator([*ws, noise], training=False)\n",
    "    df = discriminator(preds, training=False)\n",
    "    if type(verbose) == type(True):\n",
    "        verbose = [verbose for i in range(5)]\n",
    "    if type(verbose) == int:\n",
    "        if verbose == 0:\n",
    "            verbose = [False for i in range(5)]\n",
    "        elif verbose == 1:\n",
    "            verbose = [False, False, False, True, True]\n",
    "        elif verbose == 2:\n",
    "            verbose = [False, True, True, True, True]\n",
    "        elif verbose == 3:\n",
    "            verbose = [True for i in range(5)]\n",
    "            \n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[j].imshow(preds[i*cols + j] / 2 + 0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save current state of model, overwriting past state of model on disk.\n",
    "Args:\n",
    "askInp - require user to place input before saving models - protects user from accidentally overwriting models with a collapsed model\n",
    "'''\n",
    "def save_models(askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    \n",
    "    \n",
    "    generator.save_weights(modelPath+'genWeights.h5')\n",
    "    discriminator.save_weights(modelPath+'discWeights.h5')\n",
    "    mapper.save_weights(modelPath+'mapWeights.h5')\n",
    "    \n",
    "def load_models(askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    \n",
    "    \n",
    "    generator.load_weights(modelPath+'genWeights.h5')\n",
    "    discriminator.load_weights(modelPath+'discWeights.h5')\n",
    "    mapper.load_weights(modelPath+'mapWeights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_models(askInp=False)\n",
    "def image_save(path,count):\n",
    "    for i in range(count):\n",
    "        constZ = npr.randn(zdim,)\n",
    "        constNoise = npr.randn(imgSize, imgSize, 1)\n",
    "        noise=npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "        z1=npr.randn(rows * cols, zdim) \n",
    "        z2=npr.randn(rows * cols, zdim)\n",
    "        z1[0] = constZ; z2[0] = constZ; noise[0] = constNoise\n",
    "        assert z1.shape == (rows * cols, zdim)\n",
    "        assert z2.shape == (rows * cols, zdim)\n",
    "        assert noise.shape == (rows * cols, imgSize, imgSize, 1)\n",
    "            \n",
    "        randInds = npr.randint(0, 512, (rows*cols,))\n",
    "        \n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(w1_range)] + [w2 for _ in range(w2_range)]\n",
    "        preds = generator([*ws, noise], training=False)\n",
    "        for j in range(rows * cols):\n",
    "            tf.keras.preprocessing.image.array_to_img(preds[j] / 2 + 0.5).save(path+str(i*rows*cols+j)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 13:20:30.327041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-04-15 13:20:30.337804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "constZ = npr.randn(zdim,)\n",
    "rows, cols = 1, 4\n",
    "constNoise = npr.randn(imgSize, imgSize, 1)\n",
    "epoch = 0\n",
    "image_save('../../data/predict_유방/1024/',100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
